## 几个概念：
PE文件：全称是Portable Executable，意为可移植的可执行的文件，是微软Windows操作系统上的程序文件（可能是间接被执行，如DLL）。常见的EXE、DLL、OCX、SYS、COM都是PE文件。

编译：把高级语言变成计算机可以识别的二进制语言，利用编译程序从源语言编写的源程序产生目标程序的过程。

汇编：把汇编语言翻译成机器语言的过程称为汇编。
反汇编：将可执行的文件中的二进制经过分析转变为汇编程序。得到的是汇编代码。

反编译：将可执行的程序经过分析转变为高级语言的源代码格式。得到的是所用语言的源代码。

.asm file：是汇编程序文件。

.bytes file。

先对PE文件使用unpack工具，再用IDA Pro反汇编，从结果中提取opcode序列。
代码混淆工具：UPX ASPack Shell（压缩、嵌入等）
Unpack工具：PEiD

## 方法：
（一）预处理：上面操作提取出opcode序列。生成opcode序列n-gram，n取3。
控制流分析：提取可执行文件（PE文件）的CFG图（控制流图），每个block是最大连续指令块。图中每个从开始节点到结束节点的path是一个执行路径。将节点编号，表示出所有执行路径，生成CFG运行树。因为执行路径中的反向边产生循环，形成无穷opcode序列，所以检测图中的反向边并去掉。CFG运行树的root到leaf是一个完整的程序执行路径，将所有路径提取出来并串联，形成一个opcode流。然后对这个opcode流提取n-gram。

（二）特征选择：方法有Information Gain，Gain ratio，DF（document frequency），TFIDF，Chin-square testing。用的是DF和Information Gain。
DF计算：
C有两类：正常/恶意。
从正常的类取L/2个DF最大的n-gram term，再从异常的类取L/2个DF最大的n-gram term，重复的跳过。这样平衡从两个类中提取出的n-gram特征数量。

Information Gain计算：【不懂了 原来DM课讲过决策树中的Information Gain计算】。
输出1万+不同的n-gram，可经过特征选择取top400高DF或高Information Gain的n-gram term。

（三）DBN分类：
逐层贪婪与训练+监督fine-tune。
DBN的每个RBM用公式训练，然后连一起接分类层（softmax）

RBM训练方法：【图】
H层v层全连接，wji=wij wii=0

超参：隐层个数。
每个隐层节点数。

确定方法：逐渐增加隐层，观察重构error，error不变或减小的很轻微时不再增加隐层。
每层的节点数用相同方法，逐渐增加隐层节点数量，观察重构error，error不变或减小的很轻微时不再增加隐层节点数量。

最终3个200节点隐层。可见层节点数即输入维数，此处每一维是win PE文件出现这个opcode n-gran term的次数。

（四）用DBN作为autoencoder做特征提取：
DBN相当于用隐层表示原始输入数据。可以用DBN提取数据特征，做数据降维。预训练每一层作为一个simple autoencoder。
Autoencoder：下to上：编码。上to下：解码。
预训练后fine-tune：用Autoencoder error做bp（解码结果-原始输入做error？）。

## 实验：
3个ML监督学习模型做baseline：SVM，决策树，KNN。
超参设置：
KNN k=6。
决策树使用C4.5算法。
SVM核函数使用polynomial kernel。

评估：Accuracy和F1-score

数据集：
4600正常程序4600恶意程序随机分组成。

实验时这样生成数据集50次，用DBN做50次实验取平均Accuracy和F1-score。

### 实验一：特征数量和训练集数量的影响
4个训练集逐渐增加。
DF/Information Gain特征选择数量逐渐增加。
结论是特征250+，训练集1+2+3+4 stable。

### 实验二：无标签数据的影响
意义：实际应用中无标签数据远多于labeled数据。
另外准备无标签训练集，用原数据集和无标签数据及一起预训练DBN。
在labeled数据集小时，加入unlabeled数据提升效果更明显。

### 实验三：用DBN做特征表示对baseline模型效果的影响
去掉原来DBN的分类层，将最顶层隐层节点做输出。调整输出层节点数50-200，测试3个baseline model分类结果和+unlabeled data预训练DBN表示之后的分类结果。
DBN输入是直接生成的8046个3-gram opcode term。
结论是用DBN建模后再用baseline分类器比直接用baseline分类器对opcode n-gram特征分类效果好，因为DBN建模后对数据的表达力更强。
DBN也可以用来对数据降维。

各个小实验提升效果：Accuracy提升1-2 3-4百分点，F1-score提升0.01-0.02 0.05啥的。
