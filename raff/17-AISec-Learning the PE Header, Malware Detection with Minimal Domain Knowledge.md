# Learning the PE Header, Malware Detection with Minimal Domain Knowledge
# 通过最小domian knowledge（学习PE header）实现恶意代码检测

## 摘要：
两类不用domain knowledge的方法：基于byte n-gram和字符串。
将NN用于恶意代码检测和特征学习的灵活性。
限制到最小domain knowledge以提取PE头的一部分。
->NN可以从原始byte里学习，不需要显示的特征构建，效果甚至更好。(n-gram也算特征构建吧)。

PE文件：可执行文件。

## Sec3：baseline方法
两个只利用PE头信息做分类的baseline：第一个用专为解析恶意二进制中的异常header设计的库提取特征。然后讨论domain knowledge中的什么是我们所存储的特征所需要的（？）。最后我们将提出一个简单方法，domain knowledge-free的方法，用于这些字节上。这些字节仅作为神经网络输入（sec4）。

### 3.1 domain knowledge方法
原始baseline：类似PE-miner，只使用PE文件的前三个头（几乎在所有PE可执行文件中都会出现）。

PE文件->PortEX library（提取115个特征，112个数值特征3个类别特征）->RF分类器/extra random tree算法（两个都是基于树的算法，支持数值型和类别性特征。基于树的算法在这种特征上很有利，因为scale invariant）/boosted决策树算法（效果不好，并且训练时间太长）。/一些非树型算法，如linear和kernel SVM（在这种特征集合上没有树型算法效果好）。

PortEX library：设计用于真实malware头（不总是符合官方规则的）。
使用PE-miner所使用的特征的子集，测试过的所有方法都是从二进制文件的相同的固定字节范围得到特征。
多种获取malware PE头的不同库，不会总得到一致结果。用PortEX是因为他可以成功的在一个小测试中的大部分恶意代码上运行，并且好用。

提取的特征通常有很不同的scale：0/1数值，offset，filed size，大整数等。
每个model用100个树。

其他方法需要的domain knowledge：另外两方法需要用的特征子集很有限，有用的信息只有header的bytes长度，PE头的offset定位。
根据PE头规范：【此处，详细malware PE文件】
前64 Bytes：MS-Dos header
我们其他方法需要的唯一domain knowledge是Byte 0x3C处的PE头offset值。（？）
上offset的往下面走248到264字节是COFF和Optional PE头信息。（取决于32位机还是64位机，保险起见到264。有时一个field在可获取的下264字节之前结束，则补0）
总共只需提取少量行代码，比已有的解析PE头的库小很多，少花很多功夫。我们的domain knowledge方法所需要的所有信息完全包含在这328（64+264）字节中。

我们的方法需要从原始字节这种低级表示中提取信息，并达到和基于树的domain knowledge方法可比的准确性。

### 3.2 字节n-gram方法
【raff的先前工作 文献40】
特征向量为0/1值，表示一个n-gram是否存在。->Elastic-Net 正则化逻辑回归分类器。
目标函数：
 
使用这个方法是因为他会做自动特征选择（正则化的一部分），允许我们在一个单独的、计算高效的过程中考虑许多不同的特征集合的大小。
C是正则化参数，C趋于无穷时相当于标准逻辑回归。C取更小时降低模型的自由度，并且w的强度系数变为零。

不对整个文件做n-gram，我们的n-gram方法只从前面提到的与PE头相关联的byte区域提取。（类似方法，文献51，值对文件的开始和结尾字节做n-gram，基于malware更容易在这些区域被发现的假设。）
我们把byte n-gram方法作为baseline，对比最小domain knowledge方法。扩展测试n的不同取值，确保baseline尽可能强。通过在一个模型中测试包含2到6gram，发现3-gram性能表现最好，因此选用。

## Sec4：NN方法
调研了两类神经网络方法，1全连接网络，测试集上表现最好，超过所有方法。2 rnn，有更强可解释性的model，允许我们分析模型学到了什么。NN通过给定的低级特征构建自身的高级表示，PE文件的格式和行为很复杂，对于我们的需求，NN的这种性质特别理想。一个恶意作者可能故意违反格式的规则，对此domain knowledge方法会很脆弱。神经网络可以学习PE文件在实践中的使用方式，以提高性能并减少开发人员编写额外代码以处理损坏的header或处理极端情况的需求。并且网络对于新的和新鲜的输入不会产生技术错误，但手工特征提取过程可能出错。所有的网络在Keras框架下实现。

### 4.1 全连接神经网络
把328有序字节feed到model，固定长度，可以用FC。Bytes->特征向量，通过一个word2vec风格的嵌入层，嵌入层将每个字节映射为一个特定特征向量（RB空间，B是超参，定义嵌入空间维数，取了16，取更大时经过测试表现不会更好）。经过嵌入层，得到328×16=5248维的特征向量作为输入。嵌入层通过学习过程优化。
（1）使用4隐层全连接网络，经过测试加正则化会提高最高准确率。我们的场景需要的正则化方法的数量和其他领域的新鲜方法有所不同。
最终使用dropout正则化，隐层50%drop可能性，嵌入空间20%drop可能性。
（2）每个隐层后接Batch normalization，提升收敛，也起到正则化影响。
（3）Elu激活函数。（扩展Relu，保持快速收敛，改进缺点）。
（4）最近的DeCov正则化，应用于最后一个隐层，使用默认参数，DeCov正则化惩罚隐藏层的激活值之间的相关性（？），并且其应用影响网络中的所有先前层。
（5）标准权重衰减（L2正则化），每个隐层10的-4惩罚系数。第一个隐层还加了L1正则化。
L1正则化对于处理高维问题和促进稀疏有效，因为输入是5248维，所以第一隐层加了L1正则化。

### 4.2 RNN
RNN处理输入向量序列，获取隐藏状态，
测试RNN是否有能力
使用LSTM，带遗忘门。相比前馈神经网络，复杂很多，计算限制。对于这个任务来说并不实用。RNN可以处理可变长度序列，因此是。对可执行文件做domain knowledge free分类的很好的候选模型。

限制在PE头，不是做整个文件，LSTM学习好处很大，可计算性。处理整个可执行文件要百万级的timestep。（学习这样长度的序列远远超出了作者所知的任何工作的结果。）【文献16   1k字符的文本  训练生成模型  利用 truncated back-propagation（截断BP），但是模型受益于可以在每一步传播的误差信号，这种方法不适用于与生成任务相反的分类任务。】

使用嵌入层处理输入字节，然后送入RNN的每个step。

3个LSTM层，分类前attention机制，正则化（但是模型的循环性会改变正则化的影响），
用Decov正则化会抑制学习，使用50%dropout，梯度剪裁，将所有的norms剪裁为1（？）【文献35】。使用adam算法做梯度更新。

Attention机制（RNN的活跃领域）：基本motivation是通过使模型增加或减少对输入的某些部分的考虑和贡献来提高性能，并且具有通常是较大模型的可解释组件的附加benifit。
参考文献54,44 均采用多个序列作为输入通常的应用场景是RNN。

Attention机制的输出是隐层状态的加权平均：
 
Hi是step i的最后一个LSTM层的隐层激活值，ai是模型的一部分，求和为1，RNN  T个timestep的平均隐层激活值 ，提供整个序列的信息，每个hi提供序列的一个step的信息，将这些结合在一个一层小网络中（作为整个大的RNN的一部分）：
 
W0和W1是为隐层的attention机制设置的，分别关注局部和全局隐层状态激活，单独的向量v用于获取每个time step的未缩放的重要性，b是偏置项。最后使用softmax产生加权重要性，每个time step和为1（？）。
 
实现时对attention机制使用batch normalization和dropout，使用多层attention网络抑制学习，不如一层性能好。

## Sec5 实验方法与结果
总共5个模型要评估，domain knowledge baselines（在PE头特征上训练，解析出他们的逻辑组件）：Extra random trees，Random Forests。
PE header区域的Byte n-gram+逻辑回归，作为domain knowledge free的传统方法。
以上实现采用JSAT library，然后是两个神经网络方法（FC,LSTM），使用PE 头的raw bytes训练，神经网络使用keras实现。
评价指标：ROC曲线，AUC面积。通过交叉验证或测试集进行评估，
平均accuracy：正确地将所有正常代码标记为最终accuracy分数的一半，并正确标记剩余一半的所有恶意代码。 这基本上重新缩放了两个类以具有相同的权重。

数据集：
 
同文献40。两组3个测试集，Group A代表收集其他人已经用过的数据（相当于公开数据集？有微软比赛的和其他的，有网址）。Group B是一个工业合作人提供的数据，从一个大的正常和恶意可执行文件集合中采样。Group B更能代表客户机中通常的文件类型。（感觉Group B的数据集很关键，但我们搞不到）
Group A在来自微软的二进制文件上可能导致过拟合。
实验显示group A的数据容易过拟合？->因此所有模型都是在Group B上训练的。

5个model的参数设置：3-gram。基于决策树的方法100+树之后对参数变化不敏感。

NN：测试隐层size，128,256.。。2048个神经元，最后设为256。
训练35 epoch，选择性能最好的epoch的model。

### 5.1 模型结果
FC明显比基于Domain knowledge的方法好，对Group B的数据，accuracy高3-4个点，AUC高0.05多，lstm没有基于Domain knowledge的好但比byte n-gram好。
FC实用且效果好，LSTM有前景，因为能处理变长序列。
A组：FC最好，3-gram最差，LSTM/DT在不同区域表现不同。
B组：FC最好，RF也很好，其他有重叠。

PE头的二进制内容，常规的二进制格式，和图像、自然语言、信号处理等NN任务不同，这些任务有空间局部性，空间连续性，损坏后还可以通过重新来保持原始内容和语义含义（在语言任务中也可以但lower degree，通过单词替换）。使用损坏的数据对于训练神经网络和提升模型鲁棒性很有利，也体现出这种信息格式的鲁棒性。但是上面这些任务在value改变时有有意义的过渡，比如apple图经过旋转、缩放、加噪声，仍能看出是苹果图。但对于一个可执行文件，改几个bits可能意味着完全不同的行为。
相反对与二进制数据，有一些局部性，按其自然特征是变长、局部性的突然不连续（一个固有障碍）。字节值的小扰动可能导致完全不同的含义，难以做任何增强训练。即使限制在PE头，一个字节可能是逐位表示信息，也可能整个表示offset整数，可能与另一个字节合体表示一个类别选项，每种都有本质不同，必须由网络通过不同方式处理和提取。尽管raw data的行为和图像和信号任务不同，但网络有能力学习这个分类问题，这是值得一提的。这证明了NN方法的鲁棒性，并且说明使用reduced domain knowledge进行恶意软件检测是合理的。

对比全文件的n-gram【文献raff 40】：测试结果对比，只用头的content和用整个文件的byte n-gram是有可比性的。两个方法在B组测试集上差异明显。
这些结果表明，当提供适当的训练集时，来自PE头的信息可以特别好地泛化到新数据。在Group A和open malware上测试可以更好地评估我们的模型对不同人的推广。虽然改进从PE头的生成效果理想，但Group B性能太低仍是问题。尤其B组数据更好地反映了正常和恶意软件的分布。未来工作将关注为什么这些方法的泛化特征不同。

## Sec1&2
解析PE文件很难，有一些库（pefile，PortEX），开发难。
->问题都源自malware不会总按照规则编写，并且规则可能改变。
### 相关工作：
用PE头做的很高的：
（1）	文献48 PE-Miner 189特征 75个0/1表示是否import特定的DLL库
（2）	文献45 多特征，包括只来自PE头的特征，一个DDL import和函数import list。
（3）	文献10：import的函数，PE头的域（及其类型、创建时间啥的），+DT
（4）	文献46：PE头+NN 
（5）	文献10、24、32、58 ：top byte n-gram+NN（是domian无关的方法了），但有n-gram的缺点（丢失局部字串信息），n值->计算负担。

### NN类方法：
Byte字节值相比文本、信号灯task，更具有内容敏感性
（1）	文献52：在反汇编后的opcode序列上HMM
（2）	文献47：byte n-gram+first-order HMM
文章自己的RNN能够学习更高次序的依赖，HMM难以创建等级特征。
已经用过RNN的：
文献36：动态分析中手机的手工特征+RNN
文献49：通过部分反汇编的二进制，用RNN识别函数边界（这个与本文的malware detection任务不同）
【至今未发现其他用NN+原始byte序列做恶意代码检测的工作。。。。】

## Sec6：推断相关特征重要性
模型解释性：看模型学到了什么+可以用于检测过拟合。->对比domain knowledge方法使用的特征和网络学到的重要特征。
文献25：模型可解释性的讨论和定义
文献41、42、57：常见方法-可视化synthetic inputs->最大限度地激活某些神经元（会包括输出单元）
Part1 baseline的基于树的模型：
容易推断特征重要性，特征重要性score
MDI：
Gini mearure
RI（相对重要性）
->top10重要特征

Part2 LSTM模型：
每个timestep的隐层activation有一个权重，通过这些全中的值判断这个byte的重要性。LSTM逐个byte进行观察，但是Extra tree的domain knowledge特征可能是多字节范围的。不能直接比较top10->从top 70 bytes分析，这些byte对应树模型中哪些重要的特征字段。
推测FC也能学到相似的特征，但没有直接的Attention机制提供的可解释反馈（？）。->未来观察如何更好地推断特征重要性。

## Sec7 网络校准
B组测试集每个epoch进行记录，AUC稳定并且高，Accuracy波动。FC和RNN中都出现了这种行为特征。通过两图AUC对比可看到FC 1 epoch就达到高AUC，LSTM多轮之后才开始学习这个问题。
B组AUC比A组差，预期是B组好，因为和训练集数据分布一样。
A组的数据客观上比B组数据的分布简单，更容易分类得到高AUC。

问题2：Accuracy和AUC的差异问题。【根据AUC预期的accuracy比实际accuracy高的问题？】
预期是在一个度量指标上score高则在另一个上也一样，测试时error rate和AUC是一致的，但也取决于数据分布和目标函数。在我们的数据上这些score不同，open malware数据集上波动更大（因为只有恶意的。大波动说明模型在改变正常和恶意之间的交叉点，）。
->AUC是模型的ranking of data points的函数（？）
不是对数据分类做决策。【例图，看不懂这里面AUC咋算的】

问题3：
在B组训好的模型到新的数据分布上不总是校准的很好的。
对不同数据集分布的模型校准：如可以得到有限标注数据，则问题绕过（->已有的概率校准技术：文献37Platt scaling/文献56 Isotonic回归）
Platt scaling：将原始模型预测的输出作为特征。做LR回归。（没有改变决策面，而是改变了决策域）
文献34：有限数据的重校准问题，少至100个数据点的校准都能明显提升性能。【感觉就是retrain？】
实验：用测试集的一部分重校准Group A（选择每个model在测试集上accuracy最差的epoch），每个model只使用20个校准点就会大量提高准确率，（FC只用10个标注数据点就会表现更好。）

前沿校准方法：只retrain最后一层，学习一个新的决策面，其它层权重保持不变。相当于用倒数第二层的激活值重新训练一个LR回归。这种方法相比前面的简单校准（Platt scaling）需要更多的标注数据，但能更好地扩展利用预训练模型。

校准方法的原理：
随机森林和n-gram也有accuracy比给定AUC预期时低的问题，我们怀疑可能是特征源（PE头）的原因，不是因为模型或特征表示。这个问题在NN方法中更明显，因为我们将准确度绘制为训练时间的函数时，看到训练中发生了波动。 确定和更好地解决这种波动的原因 是未来工作的一个问题。

## Sec8 结论和未来工作
结论：第一个在这个任务上使用raw byte序列+NN的？？？
模型足够鲁棒->在其他domain上重训练
扩展工作：min-专家知识处理整个可执行文件->增加可用信息数量。
One-shot学习：识别新发现的malware家族类型。->决策一个新发现的malware家族的传播广泛性（不用手工构建签名）。


