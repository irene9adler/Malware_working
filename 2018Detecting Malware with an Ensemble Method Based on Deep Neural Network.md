# Detecting Malware with an Ensemble Method Based on Deep Neural Network 
## 《Security & Communication Networks》 - 2018

## 概述：
自动提取特征。
生成恶意代码灰度图->CNN+提取Opcode序列->LSTM = 集成模型做分类。

## 相关工作：【文献们】
3类恶意代码分类/检测方法：
（1）	静态分析。利用词法分析、parsing、控制流/数据流分析等技术。主要是基于指纹的方法。通过特定的手工设计的特征生成指纹。因为指纹表示了一系列固定的恶意代码特征，所以可以通过加密或迷惑来逃避检测。

（2）	动态分析。通过在虚拟机、沙箱等中运行恶意代码分析恶意代码的行为，行为有系统调用、访问网络、内存修改等。动态分析在大数据集上不够鲁棒，因为难以模拟全部引起恶意操作的场景。
综上2，迫切需要自动检测方法。

（3）	基于ML的方法。SVM，DT等。下面9个文献中的方法。

1）	使用恶意代码的3类静态特征：PE文件头，字符序列，字节序列。使用数据挖掘方法。

2）	基于规则的算法。朴素贝叶斯，对DLL数据做数据挖掘，提取字符数据和二进制序列的特征信息。

3）	提取二进制序列的n-gram特征+boost决策树。

4）	4层神经网络。提取了4类特征：熵直方图？/调用数/可执行文件metadata（这个到底是啥？）/导入的DLL。生成256维输入向量。

5）	前文，生成malware灰度图+KNN。问题是使用了全局图片特征，攻击者可以使用局部变换逃过检测。解决->

6）	对比图片特征处理和动态分析。 改进的方法对重打包过的和未重打包过得恶意代码样本效果都很好。

7）	自动恶意代码分类框架，聚类。计算距离矩阵。

8）	N-gram特征提取。KNN。还有类似的提取byte/opcode/API调用频率的n-gram。

9）	混合静态分析和动态分析提取特征，再用SVM。
以上方法问题：特征设计困难->NN自动特征提取。

## 方法：
三类特征：1malware灰度图 2opcode序列 3一些metadata特征，作为全局信息表示。

一、	malware灰度图+CNN

图片生成：用的是可执行文件，用汇编文件生成的灰度图都差不多，丢失了结构特征。8bits转为一个0-255十进制数字。用双线性插值算法形成相同size（64×64）。Size应做超参平衡准确性和计算量。

二、	opcode序列+LSTM 

2.1 IDA Pro反汇编生成opcode序列（汇编指令 asm文件），包含代码逻辑和程序执行逻辑。
【算法】Asm文件做文本，指令做词汇，做词频统计过滤低频词，用词频做特征，用随机森林做特征选择，最终得到185个指令，作为opcode set。
将asm文件每行用空格分割，匹配每个phrase与opcode set，选取在set中的并去重。

2.2 LSTM长序列训练

LSTM：处理时序数据。RNN改进，避免梯度消失。问题：难以对过长的输入序列进行有效训练。如果可执行文件很长，提取的opcode序列也会很长，平均长36000。LSTM在输入序列超过200时性能就会迅速下降。

解决：截断和填充（TAP）为固定长度N。会丢失很多信息。->truncated BPTT，加入时间窗约束，限制error bp的最大距离，梯度计算和error bp只针对窗口内的nodes。与standard BPTT（bp距离太长）比准确性会有所下降但效率会提高。
LSTM实现truncated BPTT算法：将原opcode序列分为多个子序列，长度等于时间窗长度。对每个子序列做full BPTT。可以并行在多个子序列上训练LSTM。这样3倍加速LSTM的训练（LSTM的问题是循环结构限制了连续的序列训练？）。

2.3 子序列选择和子序列合成 

经过上面的变换，LSTM的输出变为针对子序列的，也就是子序列有多大可能是恶意代码。问题：恶意代码作者经常把恶意程序段放到正常程序里，这样一个完整恶意程序的子序列可能是正常代码段。（噪声）->用LSTM做子序列选择（去燥）。LSTM输出层用逻辑回归给出属于哪一类的概率。对于恶意代码的正常子序列，其缺乏恶意代码特征，但label又是恶意的，P(1|Xj)很低。所以为极大似然概率设置阈值，过滤出P(1|Xj)很大的和很小的。
再用一个阈值n决定什么时候开始进行子序列过滤：开始训的时候参数是随机的，输出p不可靠，不过滤。计算输入的每个batch的error，当连续M个batch的error低于阈值n是触发子序列过滤。分出一个验证集，当验证集error不再减小时（？）停止子序列过滤。
->以上，得到子序列分类结果，需要合成出原序列分类结果。用加权投票法。=∑子序列权重×子序列分类结果->取最大结果。

2.4基于滑动窗口做数据扩充

类别不平衡问题，正常样本多，广泛流传的恶意代码样本多。少见的恶意代码样本少，可能被分类器忽略导致识别准确率低。需要对样本少的过采样，对样本多的负采样。
扩充样本的方法：mapping transformation。SMOTE。 不适合序列数据。->基于滑动窗口。原来分割子序列时是没有交叉的，现在加步长step控制生成的子序列数量。
【问：这样搞完感觉就是n-gram】

三、	栈式集成学习

提取metadata特征：CNN和LSTM提取的都是局部特征，用metadata特征做恶意代码的全局描述，包括：恶意代码源程序大小、二进制文件起始地址、反汇编后的文件大小、行数、不同PE片段的长度。
LSTM分类结果+CNN分类结果+metadata特征：第一层learners。
逻辑回归：第二层leaner。
用上式计算极大似然概率（？），用loss做bp更新参数theta，用SGD训练第二层leaner的逻辑回归模型。

## 实验：
一、	MalNet系统实现

（1）硬件和软件平台。
数据集：恶意代码样本是kaggle2015。2种文件：二进制文件流（去掉PE头）和对应的汇编文件。
正常程序样本是从软件提供商（Cnet，百度软件中心）获得的。
评估指标：二分类：TPR FPR EER FRR ROC。TPR反应可用性，FPR反应安全性。

（2）2种CNN实现：
BaseNet：2个卷积层，5×5卷积核，步长1，填充边缘。2个max pooling层，步长2，直接取输入的一半。一个全连接层，一个dropout正则化层。（卷积窗大，当输入小时不支持更深的网络结构->VGGNet）
VGGNet：小filter，3×3卷积核，步长1，填充边缘。3×3 max pooling，步长2。在feature map大小相同时可以处理更大的输入。结构更深：3个卷积层2个pooling层2个全连接层。
超参：激活函数 leaky relu，平均分布权重初始化（uniform distribution
weight initialization），batch normalization（提升收敛性能）。

【对比试验1】2个CNN的性能。
CNN输入是64×64灰度图，使用6折交叉验证评估两种CNN网络，对比AUC和准确性，VGGNet更好。因为网络更深可以获取更多局部信息。（网络更深训练时间更长，但VGGNet用maxout mechanism减少全连接层的节点数，网络整体参数没有变多，不会降低训练效率。）

（3）LSTM实现。
2个隐层每层185个节点（结构图啥样？），dropout正则化防过拟合（超参：dropout强度，设为0.5）。->相当于随机去掉一半节点，成为集成训练多个子网络。
Batch size30，用SGD训练Adam优化，控制学习率衰减。
首先定义了185个候选opcode集合用于从汇编程序中提取opcode序列，然后分成子序列，用Trucated BPTT训LSTM。

【对比试验2】子序列过滤的有效性和过滤比例的设置。
平衡性能和数据质量。
过滤比例90%-100%，看AUC和准确率。均比不过滤好，说明子序列过滤是有效的。过滤比例97.5%最好，过滤的太多AUC会下降，猜测因为LSTM本身有去燥能力，而过滤太多会导致训练数据不够。

【对比试验3】TAP和Trucated BPTT对比和长度参数设置
参数a。直接截断opcode序列为a VS 将opcode序列分为长度为a的子序列。
TAP会丢失信息，a越大TAP监测率越高，超过120不再增加，因为LSTM长序列有梯度消失。
Trucated BPTT a超过180检测率不再增加甚至降低，也是因为子序列的训练出现梯度消失。
LSTM最优配置表：Trucated BPTT a=120，子序列过滤比例97.5%。
LSTM只需要训1.34个小时！

（4）	集成学习

【对比试验4】baseline：n-gram+SVM。取n=1,2,3。用频率统计做特征选择，生成12834维特征向量。

【对比试验5】kaggle2015数据集，对比其他工作（有最好的2个）。
多分类问题（9类恶意代码），将最后的逻辑回归变为softmax。

各个类恶意代码样本分布不均衡问题：数据扩展。
CNN用的灰度图没有旋转不变形（会破坏纹理），也不支持倾斜变换，扩充方法：水平翻转、水平移动、纵向拉伸。
对比2个最好的方法：训练时间短，检测时间短。
Winner方法特征工程耗时长，用大规模的特征弥补专家知识。提特征要1天，训练1hour。特征工程复杂也影响检测时间。（训练是离线过程，检测是在线过程，检测耗时更重要，决定实时可用性。）DL方法耗时的是梯度计算和bp，只有训练需要，检测只需要前向计算过程。

## 讨论：
【对抗学习问题】基于ML分类器生成对抗样本【相关文献】

找到干扰项，X+干扰项=对抗样本。
计算检测结果F对样本X的梯度，来估计X的干扰项的方向？
原理：训练样本不足，不可能足够数据在全部特征空间做决策，判别模型会扩展样本和决策边界之间的距离，同时扩展特征空间中各个类别的区域。这样好处是更容易做分类，缺点是许多空间没有明确属于哪一类，可被利用生成对抗样本。

类似工作：对图片做轻微改变影响图片分类器。->近些年应用到安全领域，攻击基于ML的安全系统。->

（1）L2正则化防止过拟合。提升正常类的特征空间边界，对位置特征空间保持保守结果？避免对抗样本利用这些特征空间欺骗分类器。

（2）对抗训练。
用前面的原理（增加干扰项）制作对抗样本，加强对MalNet的训练。

（3）	集成学习增强鲁棒性。

（4）	使用不会被欺骗的特征：如opcode n-gram+LSTM。

（5）	梯度掩码：直接输出决策结果，不输出不同类别概率，attacker不能得到有用梯度来生成对抗样本。

